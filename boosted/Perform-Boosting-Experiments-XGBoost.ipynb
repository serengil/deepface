{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8133a99d",
   "metadata": {},
   "source": [
    "# Perform Experiments with DeepFace on LFW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aab0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 11:59:17.587328: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-09 11:59:17.590521: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-09 11:59:17.590530: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/sefik/.local/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# built-in dependencies\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import statistics\n",
    "\n",
    "# 3rd party dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "from deepface import DeepFace\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda3ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "detector_backend = \"retinaface\"\n",
    "more_train = False # append some of validation data into train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c9ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This experiment is done with pip package of deepface with 0.0.90 version\n"
     ]
    }
   ],
   "source": [
    "print(f\"This experiment is done with pip package of deepface with {DeepFace.__version__} version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaec973",
   "metadata": {},
   "source": [
    "### Configuration Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453104b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all configuration alternatives for 4 dimensions of arguments\n",
    "alignment = [True]\n",
    "\n",
    "models = [\"Facenet\", \"Facenet512\", \"VGG-Face\", \"ArcFace\", \"Dlib\"]\n",
    "detectors = [\"retinaface\"]\n",
    "\n",
    "metrics = [\"euclidean_l2\"]\n",
    "expand_percentage = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aeb57a",
   "metadata": {},
   "source": [
    "### Create Required Folders if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671d8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_paths = [\n",
    "    \"lfwe\",\n",
    "    \"lfwe/test\",\n",
    "    \"lfwe/train\",\n",
    "    \"lfwe/10_folds\",\n",
    "    \"dataset\",\n",
    "    \"outputs\",\n",
    "    \"outputs/test\",\n",
    "    \"outputs/train\",\n",
    "    \"outputs/10_folds\",\n",
    "    \"results\"\n",
    "]\n",
    "for target_path in target_paths:\n",
    "    if os.path.exists(target_path) != True:\n",
    "        os.mkdir(target_path)\n",
    "        print(f\"{target_path} is just created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31f03a",
   "metadata": {},
   "source": [
    "### Load LFW Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6675c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_lfe(task: str):\n",
    "    if task == \"test\":\n",
    "        instances = 1000\n",
    "    elif task == \"train\":\n",
    "        instances = 2200\n",
    "    elif task == \"10_folds\":\n",
    "        instances = 6000\n",
    "    else:\n",
    "        raise ValueError(f\"unimplemented task - {task}\")\n",
    "\n",
    "    pairs_touch = f\"outputs/{task}_lfwe.txt\"\n",
    "\n",
    "    target_path = f\"dataset/{task}_lfw.npy\"\n",
    "    labels_path = f\"dataset/{task}_labels.npy\"\n",
    "\n",
    "    if os.path.exists(target_path) != True:\n",
    "        fetched_lfw_pairs = fetch_lfw_pairs(\n",
    "            subset = task,\n",
    "            color = True,\n",
    "            # memory allocation problem occurs for validation set\n",
    "            resize = 2 if task != \"10_folds\" else 1,\n",
    "            funneled = False,\n",
    "            slice_=None,\n",
    "        )\n",
    "        print(\"fetched\")\n",
    "        pairs = fetched_lfw_pairs.pairs\n",
    "        labels = fetched_lfw_pairs.target\n",
    "        # target_names = fetched_lfw_pairs.target_names\n",
    "        np.save(target_path, pairs)\n",
    "        np.save(labels_path, labels)\n",
    "    else:\n",
    "        if os.path.exists(pairs_touch) != True:\n",
    "            # loading pairs takes some time. but if we extract these pairs as image, no need to load it anymore\n",
    "            pairs = np.load(target_path)\n",
    "        labels = np.load(labels_path)\n",
    "    \n",
    "    # store to file system\n",
    "    for i in tqdm(range(0, instances)):\n",
    "        img1_target = f\"lfwe/{task}/{i}_1.jpg\"\n",
    "        img2_target = f\"lfwe/{task}/{i}_2.jpg\"\n",
    "        \n",
    "        if os.path.exists(img1_target) != True:\n",
    "            img1 = pairs[i][0]\n",
    "            # plt.imsave(img1_target, img1/255) #works for my mac\n",
    "            plt.imsave(img1_target, img1) #works for my debian\n",
    "        \n",
    "        if os.path.exists(img2_target) != True:\n",
    "            img2 = pairs[i][1]\n",
    "            # plt.imsave(img2_target, img2/255) #works for my mac\n",
    "            plt.imsave(img2_target, img2) #works for my debian\n",
    "        \n",
    "    if os.path.exists(pairs_touch) != True:\n",
    "        open(pairs_touch,'a').close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc23313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 204430.67it/s]\n",
      "100%|██████████| 2200/2200 [00:00<00:00, 277927.44it/s]\n",
      "100%|██████████| 6000/6000 [00:00<00:00, 224941.89it/s]\n"
     ]
    }
   ],
   "source": [
    "retrieve_lfe(task = \"test\")\n",
    "retrieve_lfe(task = \"train\")\n",
    "retrieve_lfe(task = \"10_folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2e9dc",
   "metadata": {},
   "source": [
    "# Perform Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec5e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiments():    \n",
    "    for model_name in models:\n",
    "        for detector_backend in detectors:\n",
    "            for distance_metric in metrics:\n",
    "                for align in alignment:\n",
    "                    \n",
    "                    if detector_backend == \"skip\" and align is True:\n",
    "                        # Alignment is not possible for a skipped detector configuration\n",
    "                        continue\n",
    "                    \n",
    "                    calculate_distances(\n",
    "                        model_name=model_name,\n",
    "                        detector_backend=detector_backend,\n",
    "                        distance_metric=distance_metric,\n",
    "                        align=align,\n",
    "                    )\n",
    "                    \n",
    "def calculate_distances(\n",
    "        model_name: str,\n",
    "        detector_backend: str,\n",
    "        distance_metric: str = \"euclidean_l2\",\n",
    "        align: bool = True\n",
    "):\n",
    "    for experiment in [\"test\", \"train\", \"10_folds\"]:\n",
    "        if experiment == \"test\":\n",
    "            instances = 1000\n",
    "        elif experiment == \"train\":\n",
    "            instances = 2200\n",
    "        elif experiment == \"10_folds\":\n",
    "            instances = 6000\n",
    "        else:\n",
    "            raise ValueError(f\"unimplemented experiment - {experiment}\")\n",
    "\n",
    "        labels = np.load(f\"dataset/{experiment}_labels.npy\")\n",
    "\n",
    "        alignment_text = \"aligned\" if align is True else \"unaligned\"\n",
    "        task = f\"{experiment}/{model_name}_{detector_backend}_{distance_metric}_{alignment_text}\"\n",
    "        output_file = f\"outputs/{task}.csv\"\n",
    "\n",
    "        # check file is already available\n",
    "        if os.path.exists(output_file) is True:\n",
    "            continue\n",
    "        \n",
    "        distances = []\n",
    "        for i in tqdm(range(0, instances), desc = task):\n",
    "            img1_target = f\"lfwe/{experiment}/{i}_1.jpg\"\n",
    "            img2_target = f\"lfwe/{experiment}/{i}_2.jpg\"\n",
    "            result = DeepFace.verify(\n",
    "                img1_path=img1_target,\n",
    "                img2_path=img2_target,\n",
    "                model_name=model_name,\n",
    "                detector_backend=detector_backend,\n",
    "                distance_metric=distance_metric,\n",
    "                align=align,\n",
    "                enforce_detection=False,\n",
    "                expand_percentage=expand_percentage,\n",
    "            )\n",
    "            distance = result[\"distance\"]\n",
    "            distances.append(distance)\n",
    "        # -----------------------------------\n",
    "        df = pd.DataFrame(list(labels), columns = [\"actuals\"])\n",
    "        df[\"distances\"] = distances\n",
    "        df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89caa2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd2aa4",
   "metadata": {},
   "source": [
    "# Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06abec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-tuned threshold for single models\n",
    "if detector_backend == \"mtcnn\":\n",
    "    thresholds = {\n",
    "        \"Facenet\": 1.0927487190831375,\n",
    "        \"Facenet512\": 1.0676744382971612,\n",
    "        \"VGG-Face\": 1.199458073887602,\n",
    "        \"ArcFace\": 1.1853355178343647,\n",
    "        \"Dlib\": 0.4020917206804517,\n",
    "    }\n",
    "elif detector_backend == \"retinaface\":\n",
    "    thresholds = {\n",
    "        \"Facenet\": 1.0771751259493634,\n",
    "        \"Facenet512\": 1.080821730376328,\n",
    "        \"VGG-Face\": 1.1952250102966764,\n",
    "        \"ArcFace\": 1.1601818883318848,\n",
    "        \"Dlib\": 0.4022031592966787,\n",
    "    }\n",
    "elif detector_backend == \"yunet\":\n",
    "    thresholds = {\n",
    "        \"Facenet\": 1.066751738677861,\n",
    "        \"Facenet512\": 1.0691771483816928,\n",
    "        \"VGG-Face\": 1.1802823845238797,\n",
    "        \"ArcFace\": 1.1945138501899335,\n",
    "        \"Dlib\": 0.422060409585814,\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(f\"unimplemented detector - {detector_backend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1851d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"train\", \"test\", \"10_folds\"]\n",
    "\n",
    "dfs = {}\n",
    "for task in tasks:\n",
    "    dfs[task] = None\n",
    "    for model in models:\n",
    "        current_df = pd.read_csv(\n",
    "            f\"outputs/{task}/{model}_{detector_backend}_euclidean_l2_aligned.csv\"\n",
    "        ).rename(columns = {\"distances\": model})\n",
    "\n",
    "        if dfs[task] is None:\n",
    "            dfs[task] = current_df.copy()\n",
    "        else:\n",
    "            current_df = current_df.drop(columns = [\"actuals\"])\n",
    "            dfs[task] = pd.concat([dfs[task], current_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1dde8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actuals</th>\n",
       "      <th>Facenet</th>\n",
       "      <th>Facenet512</th>\n",
       "      <th>VGG-Face</th>\n",
       "      <th>ArcFace</th>\n",
       "      <th>Dlib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.665361</td>\n",
       "      <td>0.529663</td>\n",
       "      <td>0.725590</td>\n",
       "      <td>0.754328</td>\n",
       "      <td>0.241096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.761471</td>\n",
       "      <td>0.851045</td>\n",
       "      <td>0.926009</td>\n",
       "      <td>0.872847</td>\n",
       "      <td>0.361268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.929644</td>\n",
       "      <td>1.010149</td>\n",
       "      <td>0.957905</td>\n",
       "      <td>1.005725</td>\n",
       "      <td>0.320210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.298545</td>\n",
       "      <td>0.489141</td>\n",
       "      <td>0.789548</td>\n",
       "      <td>0.649016</td>\n",
       "      <td>0.259671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.613064</td>\n",
       "      <td>0.679703</td>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.950595</td>\n",
       "      <td>0.356630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actuals   Facenet  Facenet512  VGG-Face   ArcFace      Dlib\n",
       "0        1  0.665361    0.529663  0.725590  0.754328  0.241096\n",
       "1        1  0.761471    0.851045  0.926009  0.872847  0.361268\n",
       "2        1  0.929644    1.010149  0.957905  1.005725  0.320210\n",
       "3        1  0.298545    0.489141  0.789548  0.649016  0.259671\n",
       "4        1  0.613064    0.679703  0.991215  0.950595  0.356630"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa2a50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more_train=False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{more_train=}\")\n",
    "if more_train:\n",
    "    tmp_df = dfs[\"train\"].append(dfs[\"10_folds\"], ignore_index = True)\n",
    "    dfs[\"train\"] = tmp_df.sample(frac = 0.7, random_state=seed)\n",
    "    dfs[\"10_folds\"] = tmp_df.drop(dfs[\"train\"].index)\n",
    "    k = 1\n",
    "else:\n",
    "    k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f6e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_classification_results(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for model_name in models:\n",
    "        idx = df[df[model_name] < thresholds[model_name]].index\n",
    "        df[f\"{model_name}_clf\"] = -1\n",
    "        df.loc[idx, f\"{model_name}_clf\"] = 1\n",
    "    return df\n",
    "\n",
    "dfs[\"train\"] = add_classification_results(dfs[\"train\"])\n",
    "dfs[\"10_folds\"] = add_classification_results(dfs[\"10_folds\"])\n",
    "dfs[\"test\"] = add_classification_results(dfs[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128a04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_classification_sum(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"clf_sum\"] = 0\n",
    "    for model_name in models:\n",
    "        df[\"clf_sum\"] += df[f\"{model_name}_clf\"]\n",
    "    return df\n",
    "\n",
    "dfs[\"train\"] = add_classification_sum(dfs[\"train\"])\n",
    "dfs[\"10_folds\"] = add_classification_sum(dfs[\"10_folds\"])\n",
    "dfs[\"test\"] = add_classification_sum(dfs[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bcdef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_additions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"distance_sums\"] = 0\n",
    "    for model_name in models:\n",
    "        df[\"distance_sums\"] += df[f\"{model_name}\"]\n",
    "    return df\n",
    "\n",
    "dfs[\"train\"] = add_distance_additions(dfs[\"train\"])\n",
    "dfs[\"10_folds\"] = add_distance_additions(dfs[\"10_folds\"])\n",
    "dfs[\"test\"] = add_distance_additions(dfs[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c834ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_multiplications(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"distance_multiplications\"] = 1\n",
    "    for model_name in models:\n",
    "        df[\"distance_multiplications\"] *= df[f\"{model_name}\"]\n",
    "    return df\n",
    "\n",
    "dfs[\"train\"] = add_distance_multiplications(dfs[\"train\"])\n",
    "dfs[\"10_folds\"] = add_distance_multiplications(dfs[\"10_folds\"])\n",
    "dfs[\"test\"] = add_distance_multiplications(dfs[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2bc2338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actuals</th>\n",
       "      <th>Facenet</th>\n",
       "      <th>Facenet512</th>\n",
       "      <th>VGG-Face</th>\n",
       "      <th>ArcFace</th>\n",
       "      <th>Dlib</th>\n",
       "      <th>Facenet_clf</th>\n",
       "      <th>Facenet512_clf</th>\n",
       "      <th>VGG-Face_clf</th>\n",
       "      <th>ArcFace_clf</th>\n",
       "      <th>Dlib_clf</th>\n",
       "      <th>clf_sum</th>\n",
       "      <th>distance_sums</th>\n",
       "      <th>distance_multiplications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555978</td>\n",
       "      <td>0.535129</td>\n",
       "      <td>0.720907</td>\n",
       "      <td>0.774279</td>\n",
       "      <td>0.282407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.868700</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475164</td>\n",
       "      <td>0.811694</td>\n",
       "      <td>0.765939</td>\n",
       "      <td>0.168319</td>\n",
       "      <td>0.481163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.702280</td>\n",
       "      <td>0.023925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0</td>\n",
       "      <td>1.282475</td>\n",
       "      <td>1.204147</td>\n",
       "      <td>1.282847</td>\n",
       "      <td>1.243330</td>\n",
       "      <td>0.447448</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>5.460246</td>\n",
       "      <td>1.102127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0</td>\n",
       "      <td>1.238476</td>\n",
       "      <td>1.338712</td>\n",
       "      <td>1.361004</td>\n",
       "      <td>1.282596</td>\n",
       "      <td>0.463052</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>5.683840</td>\n",
       "      <td>1.340151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0</td>\n",
       "      <td>1.334190</td>\n",
       "      <td>1.365896</td>\n",
       "      <td>1.315901</td>\n",
       "      <td>1.368480</td>\n",
       "      <td>0.487813</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>5.872279</td>\n",
       "      <td>1.600847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actuals   Facenet  Facenet512  VGG-Face   ArcFace      Dlib  \\\n",
       "744         1  0.555978    0.535129  0.720907  0.774279  0.282407   \n",
       "1466        0  0.475164    0.811694  0.765939  0.168319  0.481163   \n",
       "1638        0  1.282475    1.204147  1.282847  1.243330  0.447448   \n",
       "1657        0  1.238476    1.338712  1.361004  1.282596  0.463052   \n",
       "1101        0  1.334190    1.365896  1.315901  1.368480  0.487813   \n",
       "\n",
       "      Facenet_clf  Facenet512_clf  VGG-Face_clf  ArcFace_clf  Dlib_clf  \\\n",
       "744             1               1             1            1         1   \n",
       "1466            1               1             1            1        -1   \n",
       "1638           -1              -1            -1           -1        -1   \n",
       "1657           -1              -1            -1           -1        -1   \n",
       "1101           -1              -1            -1           -1        -1   \n",
       "\n",
       "      clf_sum  distance_sums  distance_multiplications  \n",
       "744         5       2.868700                  0.046900  \n",
       "1466        3       2.702280                  0.023925  \n",
       "1638       -5       5.460246                  1.102127  \n",
       "1657       -5       5.683840                  1.340151  \n",
       "1101       -5       5.872279                  1.600847  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"train\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2443014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [column for column in dfs[\"train\"].columns if column.endswith(\"_clf\")]\n",
    "feature_names = list(dfs[\"train\"].drop(columns=[\"actuals\"]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df4d7b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36602d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore sets\n",
    "y_train = dfs[\"train\"][\"actuals\"].values\n",
    "x_train = dfs[\"train\"].drop(columns=[\"actuals\"]).values\n",
    "\n",
    "y_test = dfs[\"test\"][\"actuals\"].values\n",
    "x_test = dfs[\"test\"].drop(columns=[\"actuals\"]).values\n",
    "\n",
    "y_val = dfs[\"10_folds\"][\"actuals\"].values\n",
    "x_val = dfs[\"10_folds\"].drop(columns=[\"actuals\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f0096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.01\n",
    "    , 'max_depth': 5\n",
    "    , 'max_leaves': pow(2, 5) - 1\n",
    "    , 'n_estimators': 10000\n",
    "    , 'seed': 17\n",
    "    , 'nthread':  2\n",
    "    , 'object':  'binary:logistic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad49d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0-th model\n",
      "Training 1-th model\n",
      "Training 2-th model\n",
      "Training 3-th model\n",
      "Training 4-th model\n",
      "Training 5-th model\n",
      "Training 6-th model\n",
      "Training 7-th model\n",
      "Training 8-th model\n",
      "Training 9-th model\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for k in range(0, 10):\n",
    "    print(f\"Training {k}-th model\")\n",
    "    \n",
    "    model = xgboost.XGBClassifier(**params)\n",
    "\n",
    "    valid_from = k * 600\n",
    "    valid_until = valid_from + 600\n",
    "\n",
    "    _ = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_metric='logloss',\n",
    "        eval_set=[(x_val[valid_from:valid_until], y_val[valid_from:valid_until])],\n",
    "        early_stopping_rounds=500,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79964c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(x, y, label):\n",
    "    scores = []\n",
    "    for k in range(0, 10):\n",
    "        model = models[k]\n",
    "\n",
    "        if label == \"validation\":\n",
    "            x_org  = x.copy()\n",
    "            y_org = y.copy()\n",
    "\n",
    "            valid_from = k * 600\n",
    "            valid_until = valid_from + 600\n",
    "\n",
    "            x = x[valid_from:valid_until]\n",
    "            y = y[valid_from:valid_until]\n",
    "\n",
    "        predictions = model.predict(x)\n",
    "\n",
    "        classified = 0\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "            actual = y[idx]\n",
    "            if actual == prediction:\n",
    "                classified += 1\n",
    "\n",
    "        score = 100 * (classified / len(predictions))\n",
    "        print(round(score, 2))\n",
    "        scores.append(score)\n",
    "\n",
    "        # restore\n",
    "        if label == \"validation\":\n",
    "            x = x_org.copy()\n",
    "            y = y_org.copy()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71ba25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.73\n",
      "99.68\n",
      "99.64\n",
      "99.68\n",
      "99.73\n",
      "99.73\n",
      "99.68\n",
      "99.68\n",
      "99.68\n",
      "99.86\n"
     ]
    }
   ],
   "source": [
    "train_results = analyze_results(x_train, y_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7600f5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.71"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(train_results)/10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b2d9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.33\n",
      "97.17\n",
      "96.33\n",
      "97.17\n",
      "98.83\n",
      "98.0\n",
      "97.83\n",
      "97.5\n",
      "98.0\n",
      "98.33\n"
     ]
    }
   ],
   "source": [
    "val_results = analyze_results(x_val, y_val, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caa2d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.65"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(val_results)/10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fb56eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9\n",
      "98.9\n",
      "99.0\n",
      "99.0\n",
      "98.9\n",
      "98.8\n",
      "99.0\n",
      "98.9\n",
      "98.9\n",
      "98.8\n"
     ]
    }
   ],
   "source": [
    "test_results = analyze_results(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc0d8658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.91"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(test_results)/10, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
